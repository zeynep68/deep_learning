{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cifar10.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPlLli6+7lY/E3hD42JS/b3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zeynep68/deep_learning/blob/master/cifar10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TWd-R9LggVRh",
        "colab_type": "code",
        "outputId": "9067738e-33fb-4c36-fbe3-81fc54f43bf3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.layers import *\n",
        "from keras.regularizers import l2\n",
        "from tensorflow.keras.models import Model \n",
        "from tensorflow.keras.optimizers import *\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.initializers import *\n",
        "from tensorflow.keras.callbacks import *\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import keras"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HH5F6Mhygcb4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CIFAR10():\n",
        "    def __init__(self):\n",
        "        (self.x_train, self.y_train), (self.x_test, self.y_test) = keras.datasets.cifar10.load_data()\n",
        "\n",
        "        self.width = self.x_train.shape[1]\n",
        "        self.height = self.x_train.shape[2]\n",
        "        self.depth = self.x_train.shape[3]\n",
        "        \n",
        "        self.num_classes = np.max(self.y_train) + 1\n",
        "        \n",
        "        self.train_size = self.x_train.shape[0]\n",
        "        self.test_size = self.x_test.shape[0]\n",
        "        \n",
        "        self.y_train = to_categorical(self.y_train, self.num_classes)\n",
        "        self.y_test = to_categorical(self.y_test, self.num_classes)\n",
        "\n",
        "        self.scaler = StandardScaler()    \n",
        "\n",
        "    def get_train_set(self):\n",
        "        return self.x_train, self.y_train\n",
        "    \n",
        "    def get_test_set(self):\n",
        "        return self.x_test, self.y_test\n",
        "\n",
        "    def normalize_data(self):\n",
        "        self.scaler.fit(self.x_train.reshape(-1, 1024))\n",
        "    \n",
        "        self.x_train = self.scaler.transform(self.x_train.reshape(-1, 1024))\n",
        "        self.x_test = self.scaler.transform(self.x_test.reshape(-1,1024))\n",
        "\n",
        "        self.x_train = self.x_train.reshape((self.train_size, self.width, self.height, self.depth))\n",
        "        self.x_test = self.x_test.reshape((self.test_size, self.width, self.height, self.depth))\n",
        "        \n",
        "    def data_augmentation(self, size=5000):\n",
        "        img_generator = ImageDataGenerator(\n",
        "                            rotation_range=15,\n",
        "                            zoom_range=0.05,\n",
        "                            width_shift_range=0.1,\n",
        "                            height_shift_range=0.1,\n",
        "                            brightness_range=None,\n",
        "                            horizontal_flip=False,\n",
        "                            vertical_flip=False\n",
        "                            )\n",
        "        img_generator.fit(self.x_train, augment=True) \n",
        "\n",
        "        rand_numbers = np.random.randint(self.train_size, size=size)\n",
        "        x_augmented = np.zeros(shape=(1,self.width, self.height, self.depth))\n",
        "        y_augmented = np.zeros(shape=(1,self.num_classes))\n",
        "        \n",
        "        for i in range(size):\n",
        "            x_augmented = np.vstack((x_augmented, self.x_train[ rand_numbers[i] ].reshape(1,self.width, self.height, self.depth)))\n",
        "            y_augmented = np.vstack( (y_augmented, self.y_train[rand_numbers[i]].reshape(1,self.num_classes) ) )\n",
        "        x_augmented = np.delete(x_augmented, 0, axis=0)\n",
        "        y_augmented = np.delete(y_augmented, 0, axis=0)\n",
        "\n",
        "        x_augmented = img_generator.flow(x_augmented, np.zeros(size), batch_size=size, shuffle=False).next()[0] # next  \n",
        "\n",
        "        self.x_train = np.concatenate((self.x_train, x_augmented))\n",
        "        self.y_train = np.concatenate((self.y_train, y_augmented))\n",
        "\n",
        "        self.train_size = self.x_train.shape[0]\n",
        "\n",
        "        # Ã¤quivalent zur obigen for-schleife: \n",
        "        # x_augmented = self.x_train[rand_numbers].copy()\n",
        "        # y_augmented = self.y_train[rand_numbers].copy()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "65IxW2hLgfJG",
        "colab_type": "code",
        "outputId": "a2b1043c-a315-4ed5-d008-982e77d350cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        }
      },
      "source": [
        "if __name__ == \"__main__\":\n",
        "    cifar10 = CIFAR10()\n",
        "    img = cifar10.x_train[1]\n",
        "    #img = img.reshape(32,32,3) # just if above is valid\n",
        "    plt.imshow(img)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD5CAYAAADhukOtAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nWmKmUgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-xF_KVNDsoC3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def conv_block(input, num_filters):\n",
        "    \n",
        "    x1 = Conv2D(num_filters, kernel_size=(3,3), strides=(1,1), padding='same', kernel_initializer='he_normal', kernel_regularizer=l2(1e-4))(input)\n",
        "    x1 = BatchNormalization()(x1)\n",
        "    x1 = Activation('relu')(x1)\n",
        "\n",
        "    x1 = Conv2D(num_filters, kernel_size=(3,3), strides=(1,1), padding='same', kernel_initializer='he_normal', kernel_regularizer=l2(1e-4))(x1)\n",
        "    x1 = BatchNormalization()(x1)\n",
        "    x1 = Activation('relu')(x1)\n",
        "\n",
        "    x1 = Conv2D(num_filters, kernel_size=(3,3), strides=(1,1), padding='same', kernel_initializer='he_normal', kernel_regularizer=l2(1e-4))(x1)\n",
        "    x1 = BatchNormalization()(x1)\n",
        "\n",
        "    x2 = Conv2D(num_filters, kernel_size=(3,3), strides=(1,1), padding='same', kernel_initializer='he_normal', kernel_regularizer=l2(1e-4))(input)\n",
        "    x2 = BatchNormalization()(x2)\n",
        "\n",
        "    x = Add()([x1,x2])\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s8XEgd_Z6zb3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def identity_block(input, num_filters):\n",
        "\n",
        "    x = Conv2D(num_filters, kernel_size=(3,3), strides=(1,1), padding='same', kernel_initializer='he_normal', kernel_regularizer=l2(1e-4))(input)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    x = Conv2D(num_filters, kernel_size=(3,3), strides=(1,1), padding='same', kernel_initializer='he_normal', kernel_regularizer=l2(1e-4))(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    x = Conv2D(num_filters, kernel_size=(3,3), strides=(1,1), padding='same', kernel_initializer='he_normal', kernel_regularizer=l2(1e-4))(x)\n",
        "    x = BatchNormalization()(x)\n",
        "\n",
        "    x = Add()([x, input])\n",
        "    x = Activation('relu')(x)\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Gjfq5i1gwqH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_model(x):\n",
        "    input_img = tf.keras.Input(shape=x.shape[1:])\n",
        "\n",
        "    x = Conv2D(32, kernel_size=(7,7), strides=(1,1), padding='same', kernel_initializer='he_normal', kernel_regularizer=l2(1e-4))(input_img)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    x = MaxPool2D(pool_size=(3,3), strides=(2,2), padding='valid')(x)\n",
        "\n",
        "    x = conv_block(x, 32)\n",
        "    x = identity_block(x, 32)\n",
        "    x = identity_block(x, 32)\n",
        "\n",
        "    x = conv_block(x, 32)\n",
        "\n",
        "    x = identity_block(x, 32)\n",
        "    x = identity_block(x, 32)\n",
        "    x = identity_block(x, 32)\n",
        "\n",
        "    x = conv_block(x, 32)\n",
        "\n",
        "    x = identity_block(x, 32)\n",
        "    x = identity_block(x, 32)\n",
        "    x = identity_block(x, 32)\n",
        "    x = identity_block(x, 32)\n",
        "    x = identity_block(x, 32)\n",
        "\n",
        "    x = conv_block(x, 32)\n",
        "\n",
        "    x = identity_block(x, 32)\n",
        "    x = identity_block(x, 32)\n",
        "\n",
        "    x = AveragePooling2D(pool_size=(3,3))(x)\n",
        "\n",
        "    x = Flatten()(x)\n",
        "    y_pred = Dense(10, activation='softmax')(x)\n",
        "\n",
        "    model = Model(inputs=[input_img], outputs=[y_pred])\n",
        "\n",
        "\n",
        "    model.compile(\n",
        "                  optimizer='adam',\n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy']\n",
        "                 )\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kSpfpmj_gg6U",
        "colab_type": "code",
        "outputId": "04bf6e6c-f112-4a5a-9d3a-aef144c6caae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "cifar = CIFAR10()\n",
        "cifar.data_augmentation(size=10000)\n",
        "cifar.normalize_data()\n",
        "x_train, y_train = cifar.get_train_set()\n",
        "x_test, y_test = cifar.get_test_set()\n",
        "model = create_model(x_train)\n",
        "\n",
        "EPOCHS = 75\n",
        "BATCH_SIZE = 128\n",
        "\n",
        "training = model.fit(\n",
        "                     x_train,\n",
        "                     y_train,\n",
        "                     batch_size=BATCH_SIZE, \n",
        "                     epochs=EPOCHS,\n",
        "                     validation_data=(x_test, y_test)\n",
        "                    ) "
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/75\n",
            "469/469 [==============================] - 26s 56ms/step - loss: 2.0745 - accuracy: 0.3655 - val_loss: 1.9538 - val_accuracy: 0.4347\n",
            "Epoch 2/75\n",
            "469/469 [==============================] - 25s 54ms/step - loss: 1.6666 - accuracy: 0.5180 - val_loss: 1.7874 - val_accuracy: 0.4961\n",
            "Epoch 3/75\n",
            "469/469 [==============================] - 26s 55ms/step - loss: 1.4796 - accuracy: 0.5844 - val_loss: 1.4530 - val_accuracy: 0.5928\n",
            "Epoch 4/75\n",
            "469/469 [==============================] - 26s 55ms/step - loss: 1.3265 - accuracy: 0.6389 - val_loss: 1.3655 - val_accuracy: 0.6344\n",
            "Epoch 5/75\n",
            "469/469 [==============================] - 26s 56ms/step - loss: 1.2082 - accuracy: 0.6788 - val_loss: 1.3379 - val_accuracy: 0.6409\n",
            "Epoch 6/75\n",
            "469/469 [==============================] - 27s 57ms/step - loss: 1.1173 - accuracy: 0.7068 - val_loss: 1.3239 - val_accuracy: 0.6491\n",
            "Epoch 7/75\n",
            "469/469 [==============================] - 27s 57ms/step - loss: 1.0295 - accuracy: 0.7371 - val_loss: 1.1964 - val_accuracy: 0.6921\n",
            "Epoch 8/75\n",
            "469/469 [==============================] - 27s 57ms/step - loss: 0.9538 - accuracy: 0.7606 - val_loss: 1.2326 - val_accuracy: 0.6753\n",
            "Epoch 9/75\n",
            "469/469 [==============================] - 27s 57ms/step - loss: 0.8981 - accuracy: 0.7761 - val_loss: 1.1691 - val_accuracy: 0.6838\n",
            "Epoch 10/75\n",
            "469/469 [==============================] - 27s 57ms/step - loss: 0.8481 - accuracy: 0.7900 - val_loss: 1.0578 - val_accuracy: 0.7251\n",
            "Epoch 11/75\n",
            "469/469 [==============================] - 27s 57ms/step - loss: 0.8053 - accuracy: 0.8025 - val_loss: 1.1821 - val_accuracy: 0.6935\n",
            "Epoch 12/75\n",
            "469/469 [==============================] - 27s 58ms/step - loss: 0.7531 - accuracy: 0.8188 - val_loss: 1.0773 - val_accuracy: 0.7301\n",
            "Epoch 13/75\n",
            "469/469 [==============================] - 27s 58ms/step - loss: 0.7212 - accuracy: 0.8287 - val_loss: 1.0929 - val_accuracy: 0.7350\n",
            "Epoch 14/75\n",
            "469/469 [==============================] - 27s 58ms/step - loss: 0.6802 - accuracy: 0.8422 - val_loss: 1.1810 - val_accuracy: 0.6956\n",
            "Epoch 15/75\n",
            "469/469 [==============================] - 27s 58ms/step - loss: 0.6556 - accuracy: 0.8483 - val_loss: 1.0968 - val_accuracy: 0.7246\n",
            "Epoch 16/75\n",
            "469/469 [==============================] - 27s 58ms/step - loss: 0.6284 - accuracy: 0.8575 - val_loss: 1.0846 - val_accuracy: 0.7367\n",
            "Epoch 17/75\n",
            "469/469 [==============================] - 27s 58ms/step - loss: 0.6009 - accuracy: 0.8668 - val_loss: 1.1237 - val_accuracy: 0.7280\n",
            "Epoch 18/75\n",
            "469/469 [==============================] - 27s 58ms/step - loss: 0.5750 - accuracy: 0.8757 - val_loss: 0.9950 - val_accuracy: 0.7527\n",
            "Epoch 19/75\n",
            "469/469 [==============================] - 27s 58ms/step - loss: 0.5545 - accuracy: 0.8827 - val_loss: 1.0287 - val_accuracy: 0.7506\n",
            "Epoch 20/75\n",
            "469/469 [==============================] - 27s 58ms/step - loss: 0.5382 - accuracy: 0.8889 - val_loss: 1.0769 - val_accuracy: 0.7438\n",
            "Epoch 21/75\n",
            "469/469 [==============================] - 27s 58ms/step - loss: 0.5166 - accuracy: 0.8953 - val_loss: 1.2611 - val_accuracy: 0.7163\n",
            "Epoch 22/75\n",
            "469/469 [==============================] - 27s 58ms/step - loss: 0.5062 - accuracy: 0.8977 - val_loss: 1.0405 - val_accuracy: 0.7608\n",
            "Epoch 23/75\n",
            "469/469 [==============================] - 27s 58ms/step - loss: 0.4905 - accuracy: 0.9044 - val_loss: 1.0182 - val_accuracy: 0.7749\n",
            "Epoch 24/75\n",
            "469/469 [==============================] - 27s 58ms/step - loss: 0.4752 - accuracy: 0.9100 - val_loss: 1.0705 - val_accuracy: 0.7638\n",
            "Epoch 25/75\n",
            "469/469 [==============================] - 27s 58ms/step - loss: 0.4634 - accuracy: 0.9147 - val_loss: 1.1068 - val_accuracy: 0.7457\n",
            "Epoch 26/75\n",
            "469/469 [==============================] - 27s 57ms/step - loss: 0.4531 - accuracy: 0.9184 - val_loss: 1.1177 - val_accuracy: 0.7595\n",
            "Epoch 27/75\n",
            "469/469 [==============================] - 27s 57ms/step - loss: 0.4412 - accuracy: 0.9229 - val_loss: 1.1148 - val_accuracy: 0.7722\n",
            "Epoch 28/75\n",
            "469/469 [==============================] - 27s 57ms/step - loss: 0.4365 - accuracy: 0.9245 - val_loss: 1.1220 - val_accuracy: 0.7513\n",
            "Epoch 29/75\n",
            "469/469 [==============================] - 27s 57ms/step - loss: 0.4231 - accuracy: 0.9307 - val_loss: 1.1639 - val_accuracy: 0.7673\n",
            "Epoch 30/75\n",
            "469/469 [==============================] - 27s 57ms/step - loss: 0.4169 - accuracy: 0.9320 - val_loss: 1.3247 - val_accuracy: 0.7489\n",
            "Epoch 31/75\n",
            "469/469 [==============================] - 27s 57ms/step - loss: 0.4129 - accuracy: 0.9339 - val_loss: 1.1813 - val_accuracy: 0.7566\n",
            "Epoch 32/75\n",
            "469/469 [==============================] - 27s 57ms/step - loss: 0.4112 - accuracy: 0.9342 - val_loss: 1.1617 - val_accuracy: 0.7608\n",
            "Epoch 33/75\n",
            "469/469 [==============================] - 27s 57ms/step - loss: 0.3997 - accuracy: 0.9383 - val_loss: 1.2327 - val_accuracy: 0.7593\n",
            "Epoch 34/75\n",
            "469/469 [==============================] - 27s 57ms/step - loss: 0.3989 - accuracy: 0.9371 - val_loss: 1.2161 - val_accuracy: 0.7573\n",
            "Epoch 35/75\n",
            "469/469 [==============================] - 27s 57ms/step - loss: 0.3932 - accuracy: 0.9414 - val_loss: 1.2063 - val_accuracy: 0.7601\n",
            "Epoch 36/75\n",
            "469/469 [==============================] - 27s 57ms/step - loss: 0.3896 - accuracy: 0.9428 - val_loss: 1.2617 - val_accuracy: 0.7513\n",
            "Epoch 37/75\n",
            "469/469 [==============================] - 27s 57ms/step - loss: 0.3881 - accuracy: 0.9438 - val_loss: 1.3401 - val_accuracy: 0.7500\n",
            "Epoch 38/75\n",
            "469/469 [==============================] - 27s 57ms/step - loss: 0.3872 - accuracy: 0.9445 - val_loss: 1.3369 - val_accuracy: 0.7451\n",
            "Epoch 39/75\n",
            "469/469 [==============================] - 27s 57ms/step - loss: 0.3768 - accuracy: 0.9471 - val_loss: 1.1934 - val_accuracy: 0.7617\n",
            "Epoch 40/75\n",
            "469/469 [==============================] - 27s 57ms/step - loss: 0.3783 - accuracy: 0.9470 - val_loss: 1.2747 - val_accuracy: 0.7605\n",
            "Epoch 41/75\n",
            "469/469 [==============================] - 27s 57ms/step - loss: 0.3693 - accuracy: 0.9511 - val_loss: 1.1373 - val_accuracy: 0.7852\n",
            "Epoch 42/75\n",
            "469/469 [==============================] - 27s 57ms/step - loss: 0.3721 - accuracy: 0.9491 - val_loss: 1.3266 - val_accuracy: 0.7522\n",
            "Epoch 43/75\n",
            "469/469 [==============================] - 27s 57ms/step - loss: 0.3684 - accuracy: 0.9502 - val_loss: 1.4736 - val_accuracy: 0.7509\n",
            "Epoch 44/75\n",
            "469/469 [==============================] - 27s 57ms/step - loss: 0.3669 - accuracy: 0.9514 - val_loss: 1.4834 - val_accuracy: 0.7456\n",
            "Epoch 45/75\n",
            "469/469 [==============================] - 27s 57ms/step - loss: 0.3666 - accuracy: 0.9512 - val_loss: 1.3838 - val_accuracy: 0.7482\n",
            "Epoch 46/75\n",
            "469/469 [==============================] - 27s 57ms/step - loss: 0.3657 - accuracy: 0.9516 - val_loss: 1.5089 - val_accuracy: 0.7369\n",
            "Epoch 47/75\n",
            "469/469 [==============================] - 27s 57ms/step - loss: 0.3546 - accuracy: 0.9560 - val_loss: 1.2884 - val_accuracy: 0.7594\n",
            "Epoch 48/75\n",
            "469/469 [==============================] - 27s 57ms/step - loss: 0.3715 - accuracy: 0.9496 - val_loss: 1.4068 - val_accuracy: 0.7539\n",
            "Epoch 49/75\n",
            "469/469 [==============================] - 27s 57ms/step - loss: 0.3610 - accuracy: 0.9542 - val_loss: 1.2511 - val_accuracy: 0.7759\n",
            "Epoch 50/75\n",
            "469/469 [==============================] - 27s 57ms/step - loss: 0.3614 - accuracy: 0.9544 - val_loss: 1.3750 - val_accuracy: 0.7487\n",
            "Epoch 51/75\n",
            "469/469 [==============================] - 26s 56ms/step - loss: 0.3467 - accuracy: 0.9593 - val_loss: 1.2439 - val_accuracy: 0.7707\n",
            "Epoch 52/75\n",
            "469/469 [==============================] - 27s 57ms/step - loss: 0.3440 - accuracy: 0.9593 - val_loss: 1.3029 - val_accuracy: 0.7512\n",
            "Epoch 53/75\n",
            "469/469 [==============================] - 26s 56ms/step - loss: 0.3618 - accuracy: 0.9532 - val_loss: 1.4127 - val_accuracy: 0.7533\n",
            "Epoch 54/75\n",
            "469/469 [==============================] - 26s 56ms/step - loss: 0.3508 - accuracy: 0.9575 - val_loss: 1.4321 - val_accuracy: 0.7525\n",
            "Epoch 55/75\n",
            "469/469 [==============================] - 26s 56ms/step - loss: 0.3500 - accuracy: 0.9569 - val_loss: 1.2753 - val_accuracy: 0.7769\n",
            "Epoch 56/75\n",
            "469/469 [==============================] - 28s 59ms/step - loss: 0.3459 - accuracy: 0.9595 - val_loss: 1.2577 - val_accuracy: 0.7779\n",
            "Epoch 57/75\n",
            "469/469 [==============================] - 27s 57ms/step - loss: 0.3380 - accuracy: 0.9617 - val_loss: 1.4213 - val_accuracy: 0.7625\n",
            "Epoch 58/75\n",
            "469/469 [==============================] - 27s 57ms/step - loss: 0.3464 - accuracy: 0.9593 - val_loss: 1.3047 - val_accuracy: 0.7700\n",
            "Epoch 59/75\n",
            "469/469 [==============================] - 27s 57ms/step - loss: 0.3502 - accuracy: 0.9570 - val_loss: 1.2309 - val_accuracy: 0.7737\n",
            "Epoch 60/75\n",
            "469/469 [==============================] - 27s 57ms/step - loss: 0.3451 - accuracy: 0.9594 - val_loss: 1.5705 - val_accuracy: 0.7284\n",
            "Epoch 61/75\n",
            "469/469 [==============================] - 27s 57ms/step - loss: 0.3475 - accuracy: 0.9585 - val_loss: 1.4440 - val_accuracy: 0.7527\n",
            "Epoch 62/75\n",
            "469/469 [==============================] - 27s 57ms/step - loss: 0.3400 - accuracy: 0.9597 - val_loss: 1.3790 - val_accuracy: 0.7399\n",
            "Epoch 63/75\n",
            "469/469 [==============================] - 27s 57ms/step - loss: 0.3334 - accuracy: 0.9631 - val_loss: 1.4164 - val_accuracy: 0.7566\n",
            "Epoch 64/75\n",
            "469/469 [==============================] - 27s 57ms/step - loss: 0.3421 - accuracy: 0.9592 - val_loss: 1.4223 - val_accuracy: 0.7606\n",
            "Epoch 65/75\n",
            "469/469 [==============================] - 27s 57ms/step - loss: 0.3402 - accuracy: 0.9610 - val_loss: 1.3774 - val_accuracy: 0.7721\n",
            "Epoch 66/75\n",
            "469/469 [==============================] - 27s 57ms/step - loss: 0.3314 - accuracy: 0.9634 - val_loss: 1.2865 - val_accuracy: 0.7737\n",
            "Epoch 67/75\n",
            "469/469 [==============================] - 27s 57ms/step - loss: 0.3361 - accuracy: 0.9609 - val_loss: 1.3534 - val_accuracy: 0.7770\n",
            "Epoch 68/75\n",
            "469/469 [==============================] - 27s 57ms/step - loss: 0.3372 - accuracy: 0.9623 - val_loss: 1.4837 - val_accuracy: 0.7660\n",
            "Epoch 69/75\n",
            "469/469 [==============================] - 27s 57ms/step - loss: 0.3338 - accuracy: 0.9626 - val_loss: 1.6586 - val_accuracy: 0.7171\n",
            "Epoch 70/75\n",
            "469/469 [==============================] - 27s 57ms/step - loss: 0.3366 - accuracy: 0.9619 - val_loss: 1.6291 - val_accuracy: 0.7399\n",
            "Epoch 71/75\n",
            "469/469 [==============================] - 27s 57ms/step - loss: 0.3370 - accuracy: 0.9607 - val_loss: 1.4316 - val_accuracy: 0.7600\n",
            "Epoch 72/75\n",
            "469/469 [==============================] - 27s 57ms/step - loss: 0.3276 - accuracy: 0.9641 - val_loss: 1.3492 - val_accuracy: 0.7696\n",
            "Epoch 73/75\n",
            "469/469 [==============================] - 27s 57ms/step - loss: 0.3288 - accuracy: 0.9640 - val_loss: 1.5485 - val_accuracy: 0.7541\n",
            "Epoch 74/75\n",
            "469/469 [==============================] - 27s 57ms/step - loss: 0.3332 - accuracy: 0.9619 - val_loss: 1.5502 - val_accuracy: 0.7506\n",
            "Epoch 75/75\n",
            "469/469 [==============================] - 27s 57ms/step - loss: 0.3283 - accuracy: 0.9642 - val_loss: 1.4251 - val_accuracy: 0.7612\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6LhOwxPAglrH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b4f9d474-3960-4a07-e513-976e89862ad5"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 32, 32, 32)   4736        input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 32, 32, 32)   128         conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 32, 32, 32)   0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 15, 15, 32)   0           activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 15, 15, 32)   9248        max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 15, 15, 32)   128         conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 15, 15, 32)   0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 15, 15, 32)   9248        activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 15, 15, 32)   128         conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 15, 15, 32)   0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 15, 15, 32)   9248        activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 15, 15, 32)   9248        max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 15, 15, 32)   128         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 15, 15, 32)   128         conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add (Add)                       (None, 15, 15, 32)   0           batch_normalization_3[0][0]      \n",
            "                                                                 batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 15, 15, 32)   0           add[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 15, 15, 32)   9248        activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 15, 15, 32)   128         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 15, 15, 32)   0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 15, 15, 32)   9248        activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 15, 15, 32)   128         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 15, 15, 32)   0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 15, 15, 32)   9248        activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 15, 15, 32)   128         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 15, 15, 32)   0           batch_normalization_7[0][0]      \n",
            "                                                                 activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 15, 15, 32)   0           add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 15, 15, 32)   9248        activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 15, 15, 32)   128         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 15, 15, 32)   0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 15, 15, 32)   9248        activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 15, 15, 32)   128         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 15, 15, 32)   0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 15, 15, 32)   9248        activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 15, 15, 32)   128         conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 15, 15, 32)   0           batch_normalization_10[0][0]     \n",
            "                                                                 activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 15, 15, 32)   0           add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 15, 15, 32)   9248        activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 15, 15, 32)   128         conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 15, 15, 32)   0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 15, 15, 32)   9248        activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 15, 15, 32)   128         conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 15, 15, 32)   0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 15, 15, 32)   9248        activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 15, 15, 32)   9248        activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 15, 15, 32)   128         conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 15, 15, 32)   128         conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 15, 15, 32)   0           batch_normalization_13[0][0]     \n",
            "                                                                 batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 15, 15, 32)   0           add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 15, 15, 32)   9248        activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 15, 15, 32)   128         conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 15, 15, 32)   0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 15, 15, 32)   9248        activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 15, 15, 32)   128         conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 15, 15, 32)   0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 15, 15, 32)   9248        activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 15, 15, 32)   128         conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, 15, 15, 32)   0           batch_normalization_17[0][0]     \n",
            "                                                                 activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 15, 15, 32)   0           add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 15, 15, 32)   9248        activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 15, 15, 32)   128         conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 15, 15, 32)   0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 15, 15, 32)   9248        activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 15, 15, 32)   128         conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 15, 15, 32)   0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 15, 15, 32)   9248        activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 15, 15, 32)   128         conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, 15, 15, 32)   0           batch_normalization_20[0][0]     \n",
            "                                                                 activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 15, 15, 32)   0           add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 15, 15, 32)   9248        activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 15, 15, 32)   128         conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 15, 15, 32)   0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 15, 15, 32)   9248        activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 15, 15, 32)   128         conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 15, 15, 32)   0           batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 15, 15, 32)   9248        activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 15, 15, 32)   128         conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_6 (Add)                     (None, 15, 15, 32)   0           batch_normalization_23[0][0]     \n",
            "                                                                 activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 15, 15, 32)   0           add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 15, 15, 32)   9248        activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, 15, 15, 32)   128         conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 15, 15, 32)   0           batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 15, 15, 32)   9248        activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, 15, 15, 32)   128         conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 15, 15, 32)   0           batch_normalization_25[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 15, 15, 32)   9248        activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 15, 15, 32)   9248        activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, 15, 15, 32)   128         conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_27 (BatchNo (None, 15, 15, 32)   128         conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_7 (Add)                     (None, 15, 15, 32)   0           batch_normalization_26[0][0]     \n",
            "                                                                 batch_normalization_27[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 15, 15, 32)   0           add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 15, 15, 32)   9248        activation_24[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_28 (BatchNo (None, 15, 15, 32)   128         conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 15, 15, 32)   0           batch_normalization_28[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 15, 15, 32)   9248        activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_29 (BatchNo (None, 15, 15, 32)   128         conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 15, 15, 32)   0           batch_normalization_29[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 15, 15, 32)   9248        activation_26[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_30 (BatchNo (None, 15, 15, 32)   128         conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_8 (Add)                     (None, 15, 15, 32)   0           batch_normalization_30[0][0]     \n",
            "                                                                 activation_24[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 15, 15, 32)   0           add_8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 15, 15, 32)   9248        activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_31 (BatchNo (None, 15, 15, 32)   128         conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 15, 15, 32)   0           batch_normalization_31[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 15, 15, 32)   9248        activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_32 (BatchNo (None, 15, 15, 32)   128         conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 15, 15, 32)   0           batch_normalization_32[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 15, 15, 32)   9248        activation_29[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_33 (BatchNo (None, 15, 15, 32)   128         conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_9 (Add)                     (None, 15, 15, 32)   0           batch_normalization_33[0][0]     \n",
            "                                                                 activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 15, 15, 32)   0           add_9[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 15, 15, 32)   9248        activation_30[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_34 (BatchNo (None, 15, 15, 32)   128         conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 15, 15, 32)   0           batch_normalization_34[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 15, 15, 32)   9248        activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_35 (BatchNo (None, 15, 15, 32)   128         conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 15, 15, 32)   0           batch_normalization_35[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 15, 15, 32)   9248        activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_36 (BatchNo (None, 15, 15, 32)   128         conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_10 (Add)                    (None, 15, 15, 32)   0           batch_normalization_36[0][0]     \n",
            "                                                                 activation_30[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 15, 15, 32)   0           add_10[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 15, 15, 32)   9248        activation_33[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_37 (BatchNo (None, 15, 15, 32)   128         conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 15, 15, 32)   0           batch_normalization_37[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 15, 15, 32)   9248        activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_38 (BatchNo (None, 15, 15, 32)   128         conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 15, 15, 32)   0           batch_normalization_38[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 15, 15, 32)   9248        activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_39 (BatchNo (None, 15, 15, 32)   128         conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_11 (Add)                    (None, 15, 15, 32)   0           batch_normalization_39[0][0]     \n",
            "                                                                 activation_33[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 15, 15, 32)   0           add_11[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, 15, 15, 32)   9248        activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_40 (BatchNo (None, 15, 15, 32)   128         conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 15, 15, 32)   0           batch_normalization_40[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, 15, 15, 32)   9248        activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_41 (BatchNo (None, 15, 15, 32)   128         conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 15, 15, 32)   0           batch_normalization_41[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, 15, 15, 32)   9248        activation_38[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_42 (BatchNo (None, 15, 15, 32)   128         conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_12 (Add)                    (None, 15, 15, 32)   0           batch_normalization_42[0][0]     \n",
            "                                                                 activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 15, 15, 32)   0           add_12[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_43 (Conv2D)              (None, 15, 15, 32)   9248        activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_43 (BatchNo (None, 15, 15, 32)   128         conv2d_43[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 15, 15, 32)   0           batch_normalization_43[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, 15, 15, 32)   9248        activation_40[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_44 (BatchNo (None, 15, 15, 32)   128         conv2d_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 15, 15, 32)   0           batch_normalization_44[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_45 (Conv2D)              (None, 15, 15, 32)   9248        activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_46 (Conv2D)              (None, 15, 15, 32)   9248        activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_45 (BatchNo (None, 15, 15, 32)   128         conv2d_45[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_46 (BatchNo (None, 15, 15, 32)   128         conv2d_46[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_13 (Add)                    (None, 15, 15, 32)   0           batch_normalization_45[0][0]     \n",
            "                                                                 batch_normalization_46[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 15, 15, 32)   0           add_13[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_47 (Conv2D)              (None, 15, 15, 32)   9248        activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_47 (BatchNo (None, 15, 15, 32)   128         conv2d_47[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 15, 15, 32)   0           batch_normalization_47[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_48 (Conv2D)              (None, 15, 15, 32)   9248        activation_43[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_48 (BatchNo (None, 15, 15, 32)   128         conv2d_48[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 15, 15, 32)   0           batch_normalization_48[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_49 (Conv2D)              (None, 15, 15, 32)   9248        activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_49 (BatchNo (None, 15, 15, 32)   128         conv2d_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_14 (Add)                    (None, 15, 15, 32)   0           batch_normalization_49[0][0]     \n",
            "                                                                 activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 15, 15, 32)   0           add_14[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_50 (Conv2D)              (None, 15, 15, 32)   9248        activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_50 (BatchNo (None, 15, 15, 32)   128         conv2d_50[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 15, 15, 32)   0           batch_normalization_50[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_51 (Conv2D)              (None, 15, 15, 32)   9248        activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_51 (BatchNo (None, 15, 15, 32)   128         conv2d_51[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 15, 15, 32)   0           batch_normalization_51[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_52 (Conv2D)              (None, 15, 15, 32)   9248        activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_52 (BatchNo (None, 15, 15, 32)   128         conv2d_52[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_15 (Add)                    (None, 15, 15, 32)   0           batch_normalization_52[0][0]     \n",
            "                                                                 activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 15, 15, 32)   0           add_15[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d (AveragePooli (None, 5, 5, 32)     0           activation_48[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 800)          0           average_pooling2d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 10)           8010        flatten[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 500,426\n",
            "Trainable params: 497,034\n",
            "Non-trainable params: 3,392\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZBAKCvO2jnX7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "0c43b1f0-12da-4551-97f2-be4abb9d74ae"
      },
      "source": [
        "print(\"Test set result after whole training\")\n",
        "validation = model.evaluate(x_test, y_test, batch_size=BATCH_SIZE)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test set result after whole training\n",
            "79/79 [==============================] - 1s 14ms/step - loss: 1.4251 - accuracy: 0.7612\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}